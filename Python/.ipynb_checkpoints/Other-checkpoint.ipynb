{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取mat格式的数据\n",
    "data0 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data2_train.mat')['data2_train']\n",
    "data1 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data3_train.mat')['data3_train']\n",
    "data2 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data5_train.mat')['data5_train']\n",
    "data3 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data6_train.mat')['data6_train']\n",
    "data4 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data8_train.mat')['data8_train']\n",
    "data5 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data10_train.mat')['data10_train']\n",
    "data6 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data11_train.mat')['data11_train']\n",
    "data7 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data12_train.mat')['data12_train']\n",
    "data8 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data14_train.mat')['data14_train']\n",
    "\n",
    "a = [2, 3, 5, 6, 8, 10, 11, 12, 14]\n",
    "b = 2 * np.ones(data0.shape[0])\n",
    "\n",
    "datas = [data0, data1, data2, data3, data4, data5, data6, data7, data8]\n",
    "i = 0\n",
    "for i in range(9):\n",
    "    b = a[i] * np.ones((datas[i]).shape[0])\n",
    "    datas[i] = np.c_[datas[i], b]\n",
    "    #print(datas[i].shape)\n",
    "\n",
    "for i in range(8):\n",
    "    datas[i+1] = np.vstack((datas[i], datas[i+1]))\n",
    "#print(datas[8].shape)\n",
    "data = datas[8]\n",
    "#标准化数据\n",
    "data_D = preprocessing.StandardScaler().fit_transform(data[:,:-1])\n",
    "data_L = data[:, -1]\n",
    "#print(data)\n",
    "\n",
    "#划分数据集训练集\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_D, data_L, test_size = 0.2, random_state = 7,\n",
    "                                                                  stratify = data_L)\n",
    "\n",
    "#模型训练\n",
    "clf = SVC(kernel='rbf',gamma=0.125,C=10)\n",
    "clf.fit(data_train,label_train)\n",
    "pred = clf.predict(data_test)\n",
    "accuracy = metrics.accuracy_score(label_test, pred)*100\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(clf, \"MODEL.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import RandomizedLogisticRegression as RLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取mat格式的数据\n",
    "data0 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data2_train.mat')['data2_train']\n",
    "data1 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data3_train.mat')['data3_train']\n",
    "data2 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data5_train.mat')['data5_train']\n",
    "data3 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data6_train.mat')['data6_train']\n",
    "data4 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data8_train.mat')['data8_train']\n",
    "data5 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data10_train.mat')['data10_train']\n",
    "data6 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data11_train.mat')['data11_train']\n",
    "data7 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data12_train.mat')['data12_train']\n",
    "data8 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data14_train.mat')['data14_train']\n",
    "\n",
    "a = [2, 3, 5, 6, 8, 10, 11, 12, 14]\n",
    "b = 2 * np.ones(data0.shape[0])\n",
    "\n",
    "datas = [data0, data1, data2, data3, data4, data5, data6, data7, data8]\n",
    "i = 0\n",
    "for i in range(9):\n",
    "    b = a[i] * np.ones((datas[i]).shape[0])\n",
    "    datas[i] = np.c_[datas[i], b]\n",
    "    #print(datas[i].shape)\n",
    "\n",
    "for i in range(8):\n",
    "    datas[i+1] = np.vstack((datas[i], datas[i+1]))\n",
    "#print(datas[8].shape)\n",
    "data = datas[8]\n",
    "#标准化数据\n",
    "data_D = data[:, :-1]#preprocessing.StandardScaler().fit_transform(data[:,:-1])\n",
    "data_L = data[:, -1]\n",
    "#print(data)\n",
    "\n",
    "#划分数据集训练集\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_D, data_L, test_size = 0.2, random_state = 7,\n",
    "                                                                  stratify = data_L)\n",
    "\n",
    "\n",
    "#模型训练\n",
    "#model = DecisionTreeClassifier(random_state = 0, max_depth = 5)\n",
    "#model = model.fit(data_train, label_train)\n",
    "#print('模型的平均正确率为：',model.score(data_test, label_test))\n",
    "#print ('模型的平均正确率为：',model.score(test_X, test_y))\n",
    "\n",
    "print(data_L)\n",
    "print(data_D)\n",
    "print(data_train.shape)\n",
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile = 65)\n",
    "x_train_fs = fs.fit_transform(data_train, label_train)\n",
    "x_test_fs = fs.transform(data_test)\n",
    "dt.fit(x_train_fs, label_train)\n",
    "print(\"前10%特征的学习模型预测准确率：\", dt.score(x_test_fs, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import  LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#获取mat格式的数据\n",
    "data0 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data2_train.mat')['data2_train']\n",
    "data1 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data3_train.mat')['data3_train']\n",
    "data2 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data5_train.mat')['data5_train']\n",
    "data3 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data6_train.mat')['data6_train']\n",
    "data4 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data8_train.mat')['data8_train']\n",
    "data5 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data10_train.mat')['data10_train']\n",
    "data6 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data11_train.mat')['data11_train']\n",
    "data7 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data12_train.mat')['data12_train']\n",
    "data8 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data14_train.mat')['data14_train']\n",
    "\n",
    "a = [2, 3, 5, 6, 8, 10, 11, 12, 14]\n",
    "b = 2 * np.ones(data0.shape[0])\n",
    "\n",
    "datas = [data0, data1, data2, data3, data4, data5, data6, data7, data8]\n",
    "i = 0\n",
    "for i in range(9):\n",
    "    b = a[i] * np.ones((datas[i]).shape[0])\n",
    "    datas[i] = np.c_[datas[i], b]\n",
    "    #print(datas[i].shape)\n",
    "\n",
    "for i in range(8):\n",
    "    datas[i+1] = np.vstack((datas[i], datas[i+1]))\n",
    "#print(datas[8].shape)\n",
    "data = datas[8]\n",
    "#标准化数据\n",
    "data_D = preprocessing.StandardScaler().fit_transform(data[:,:-1])\n",
    "data_L = data[:, -1]\n",
    "names = []\n",
    "for i in range(200):\n",
    "    names.append(i)\n",
    "\n",
    "#划分数据集训练集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_D, data_L, test_size = 0.2, random_state = 7,\n",
    "                                                                  stratify = data_L)\n",
    "\n",
    "\n",
    "#cross validation\n",
    "folds = 29\n",
    "C_choices = [5,13,20,25]\n",
    "C_loss = []\n",
    "C_accuracy = []\n",
    " \n",
    "for c in C_choices:\n",
    "    svc = SVC(kernel ='rbf',gamma=0.125,C = c)\n",
    "    accuracy = cross_val_score(svc, X_train, Y_train, cv = 10, scoring = 'accuracy')\n",
    "    loss = -cross_val_score(svc, X_train, Y_train, cv = 10,scoring = 'neg_mean_squared_error')#for regression    损失函数\n",
    "    C_accuracy.append(accuracy.mean())#计算均值得分\n",
    "    print(C_accuracy)\n",
    "    C_loss.append(loss.mean())\n",
    "    print(C_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(C_choices,C_accuracy)\n",
    "plt.xlabel(\"Value of C for SVC\")\n",
    "plt.ylabel(\"Cross-validates Accuracy\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(C_choices,C_loss)\n",
    "plt.xlabel(\"Value of C for CNN\")\n",
    "plt.ylabel(\"Cross-validates Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds = []\n",
    "y_folds = []\n",
    " \n",
    "X_folds = np.vsplit(X_train,folds)\n",
    "y_folds = np.hsplit(Y_train,folds)\n",
    " \n",
    "accuracy_of_C = {}\n",
    "for c in C_choices:\n",
    "    accuracy_of_C[c] = []\n",
    "#split the train sets and validation sets\n",
    "for i in range(folds):\n",
    "    X_train =np.vstack(X_folds[:i] + X_folds[i+1:]) \n",
    "    X_val = X_folds[i]\n",
    "    y_train = np.hstack(y_folds[:i] + y_folds[i+1:])\n",
    "    y_val = y_folds[i]\n",
    "    print(X_train.shape,X_val.shape,y_train.shape,y_val.shape)\n",
    "    for c in C_choices:\n",
    "        classify = SVC(kernel ='rbf',gamma=0.125,C = c)\n",
    "        classify.fit(X_train,y_train)\n",
    "        y_val_pred = classify.predict(X_val)\n",
    "        accuracy = np.mean(y_val_pred == y_val)\n",
    "        accuracy_of_C[c].append(accuracy)\n",
    "        \n",
    "        \n",
    "for c in sorted(C_choices):\n",
    "    accuracy_of_C[c] = np.array(accuracy_of_C[c])\n",
    "    accuracy = np.sum(accuracy_of_C[c])\n",
    "    accuracy = accuracy / 20\n",
    "    print('C = %d,accuracy = %f' %(c,accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
