{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.获取本地数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取mat格式的数据\n",
    "data0 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data2_train.mat')['data2_train']\n",
    "data1 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data3_train.mat')['data3_train']\n",
    "data2 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data5_train.mat')['data5_train']\n",
    "data3 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data6_train.mat')['data6_train']\n",
    "data4 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data8_train.mat')['data8_train']\n",
    "data5 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data10_train.mat')['data10_train']\n",
    "data6 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data11_train.mat')['data11_train']\n",
    "data7 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data12_train.mat')['data12_train']\n",
    "data8 = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/train/data14_train.mat')['data14_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将已知类别添加到相应数据中\n",
    "a = [2, 3, 5, 6, 8, 10, 11, 12, 14]\n",
    "\n",
    "datas = [data0, data1, data2, data3, data4, data5, data6, data7, data8]\n",
    "i = 0\n",
    "for i in range(9):\n",
    "    b = a[i] * np.ones((datas[i]).shape[0])\n",
    "    datas[i] = np.c_[datas[i], b]\n",
    "    #print(datas[i].shape)\n",
    "\n",
    "#将9个类别合并为一个数组\n",
    "for i in range(8):\n",
    "    datas[i+1] = np.vstack((datas[i], datas[i+1]))\n",
    "#print(datas[8].shape)\n",
    "data = datas[8]\n",
    "#标准化数据\n",
    "data_D = preprocessing.StandardScaler().fit_transform(data[:,:-1])\n",
    "data_L = data[:, -1]\n",
    "\n",
    "X = data_D\n",
    "Y = data_L\n",
    "\n",
    "#划分数据集训练集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_D, data_L, test_size = 0.2, random_state = 7, stratify = data_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8736462093862816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "rf = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rf.fit(X_train, Y_train)\n",
    "score = rf.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.验证集调参优化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8736462093862816\n",
      "0.7646209386281588\n",
      "0.8462093862815885\n",
      "0.8613718411552347\n",
      "0.8794223826714801\n",
      "0.8909747292418773\n",
      "0.8880866425992779\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8916967509025271\n",
      "0.8967509025270758\n",
      "0.8996389891696751\n",
      "0.9003610108303249\n",
      "0.9054151624548736\n",
      "0.9025270758122743\n",
      "0.903971119133574\n",
      "0.9025270758122743\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9075812274368231\n",
      "0.9054151624548736\n",
      "0.9032490974729241\n",
      "0.9018050541516246\n",
      "0.9025270758122743\n",
      "0.903971119133574\n",
      "0.9046931407942238\n",
      "0.9025270758122743\n",
      "0.9032490974729241\n",
      "0.9061371841155235\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9061371841155235\n",
      "0.903971119133574\n",
      "0.9046931407942238\n",
      "0.908303249097473\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9046931407942238\n",
      "0.9032490974729241\n",
      "0.9032490974729241\n",
      "0.9054151624548736\n",
      "0.9068592057761733\n",
      "0.9032490974729241\n",
      "0.903971119133574\n",
      "0.9046931407942238\n",
      "0.9054151624548736\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9061371841155235\n",
      "0.9054151624548736\n",
      "0.9068592057761733\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.908303249097473\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9054151624548736\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9068592057761733\n",
      "0.908303249097473\n",
      "0.908303249097473\n",
      "0.9075812274368231\n",
      "0.908303249097473\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9090252707581228\n",
      "0.9090252707581228\n",
      "0.908303249097473\n",
      "0.9097472924187726\n",
      "0.9090252707581228\n",
      "0.9075812274368231\n",
      "0.908303249097473\n",
      "0.908303249097473\n",
      "0.9090252707581228\n",
      "0.908303249097473\n",
      "0.9104693140794223\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.908303249097473\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9046931407942238\n",
      "0.9061371841155235\n",
      "0.9054151624548736\n",
      "0.9054151624548736\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9075812274368231\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9068592057761733\n",
      "0.9061371841155235\n",
      "0.9061371841155235\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.903971119133574\n",
      "0.9054151624548736\n",
      "0.9046931407942238\n",
      "0.768231046931408\n",
      "0.8613718411552347\n",
      "0.8714801444043321\n",
      "0.8707581227436824\n",
      "0.8844765342960289\n",
      "0.8866425992779784\n",
      "0.8866425992779784\n",
      "0.8909747292418773\n",
      "0.8844765342960289\n",
      "0.8873646209386281\n",
      "0.8844765342960289\n",
      "0.8880866425992779\n",
      "0.8888086642599278\n",
      "0.8902527075812274\n",
      "0.8873646209386281\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8909747292418773\n",
      "0.8938628158844766\n",
      "0.8902527075812274\n",
      "0.8888086642599278\n",
      "0.8895306859205776\n",
      "0.8931407942238268\n",
      "0.8909747292418773\n",
      "0.8916967509025271\n",
      "0.8909747292418773\n",
      "0.8902527075812274\n",
      "0.8902527075812274\n",
      "0.8916967509025271\n",
      "0.8902527075812274\n",
      "0.8902527075812274\n",
      "0.8916967509025271\n",
      "0.8924187725631769\n",
      "0.8916967509025271\n",
      "0.8916967509025271\n",
      "0.8916967509025271\n",
      "0.8924187725631769\n",
      "0.8916967509025271\n",
      "0.8916967509025271\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8924187725631769\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8916967509025271\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8953068592057761\n",
      "0.8938628158844766\n",
      "0.8931407942238268\n",
      "0.8924187725631769\n",
      "0.8916967509025271\n",
      "0.8931407942238268\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8931407942238268\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8953068592057761\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8909747292418773\n",
      "0.8916967509025271\n",
      "0.8924187725631769\n",
      "0.8924187725631769\n",
      "0.8931407942238268\n",
      "0.8924187725631769\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8916967509025271\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8967509025270758\n",
      "0.8967509025270758\n",
      "0.8953068592057761\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8924187725631769\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8916967509025271\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8924187725631769\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8931407942238268\n",
      "0.8931407942238268\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8945848375451263\n",
      "0.8938628158844766\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.8967509025270758\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.8945848375451263\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.8945848375451263\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.8967509025270758\n",
      "0.8953068592057761\n",
      "0.8967509025270758\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8967509025270758\n",
      "0.8967509025270758\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.8953068592057761\n",
      "0.896028880866426\n",
      "0.896028880866426\n",
      "0.8967509025270758\n",
      "0.752346570397112\n",
      "0.8476534296028881\n",
      "0.8469314079422383\n",
      "0.8548736462093863\n",
      "0.8649819494584837\n",
      "0.8700361010830325\n",
      "0.8649819494584837\n",
      "0.8685920577617329\n",
      "0.8693140794223827\n",
      "0.867870036101083\n",
      "0.8671480144404332\n",
      "0.8700361010830325\n",
      "0.8693140794223827\n",
      "0.8722021660649819\n",
      "0.8693140794223827\n",
      "0.8693140794223827\n",
      "0.8729241877256317\n",
      "0.8714801444043321\n",
      "0.8707581227436824\n",
      "0.8758122743682311\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8787003610108304\n",
      "0.8779783393501805\n",
      "0.8758122743682311\n",
      "0.8765342960288809\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8787003610108304\n",
      "0.8772563176895307\n",
      "0.8801444043321299\n",
      "0.8794223826714801\n",
      "0.8801444043321299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8808664259927798\n",
      "0.8823104693140794\n",
      "0.8815884476534296\n",
      "0.8823104693140794\n",
      "0.8808664259927798\n",
      "0.8823104693140794\n",
      "0.8808664259927798\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8801444043321299\n",
      "0.8794223826714801\n",
      "0.8794223826714801\n",
      "0.8815884476534296\n",
      "0.8794223826714801\n",
      "0.8823104693140794\n",
      "0.8823104693140794\n",
      "0.8837545126353791\n",
      "0.8830324909747292\n",
      "0.8830324909747292\n",
      "0.8823104693140794\n",
      "0.8830324909747292\n",
      "0.8815884476534296\n",
      "0.8801444043321299\n",
      "0.8815884476534296\n",
      "0.8808664259927798\n",
      "0.8808664259927798\n",
      "0.8815884476534296\n",
      "0.8823104693140794\n",
      "0.8815884476534296\n",
      "0.8808664259927798\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8808664259927798\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8815884476534296\n",
      "0.8808664259927798\n",
      "0.8808664259927798\n",
      "0.8823104693140794\n",
      "0.8808664259927798\n",
      "0.8808664259927798\n",
      "0.8801444043321299\n",
      "0.8801444043321299\n",
      "0.8801444043321299\n",
      "0.8808664259927798\n",
      "0.8808664259927798\n",
      "0.8815884476534296\n",
      "0.8801444043321299\n",
      "0.8794223826714801\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8787003610108304\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8787003610108304\n",
      "0.8772563176895307\n",
      "0.8758122743682311\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8758122743682311\n",
      "0.8750902527075812\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8750902527075812\n",
      "0.8758122743682311\n",
      "0.8743682310469314\n",
      "0.8750902527075812\n",
      "0.8750902527075812\n",
      "0.8750902527075812\n",
      "0.8758122743682311\n",
      "0.8750902527075812\n",
      "0.8750902527075812\n",
      "0.8758122743682311\n",
      "0.8750902527075812\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8787003610108304\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8787003610108304\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8779783393501805\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8779783393501805\n",
      "0.8772563176895307\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8765342960288809\n",
      "0.8772563176895307\n",
      "0.8772563176895307\n",
      "(1, 466, 0.9104693140794223)\n"
     ]
    }
   ],
   "source": [
    "#验证集调参\n",
    "results = []\n",
    "sample_leaf_options = list(range(1, 10, 3)) # 决策树个数参数取值\n",
    "n_estimators_options = list(range(1, 1000, 5))\n",
    "\n",
    "for leaf_size in sample_leaf_options:\n",
    "    for n_estimators_size in n_estimators_options:\n",
    "        rf = RandomForestClassifier(min_samples_leaf=leaf_size, n_estimators=n_estimators_size, random_state=50)\n",
    "        rf.fit(X_train, Y_train)\n",
    "        predict = rf.predict(X_test)\n",
    "        # 用一个三元组，分别记录当前的 min_samples_leaf，n_estimators， 和在测试数据集上的精度\n",
    "        results.append((leaf_size, n_estimators_size, (Y_test == predict).mean()))\n",
    "        # 真实结果和预测结果进行比较，计算准确率\n",
    "        print((Y_test == predict).mean())\n",
    "# 打印精度最大的那一个三元组\n",
    "print(max(results, key=lambda x: x[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.选取最优模型对测试集进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf = 1, n_estimators = 466, random_state = 50)\n",
    "\n",
    "#模型训练\n",
    "rf.fit(X_train, Y_train)\n",
    "score = rf.score(X_test, Y_test)\n",
    "print('%.2f%%'%(score*100))\n",
    "\n",
    "#测试集导入数据\n",
    "data = loadmat('/media/wangziwei/LENOVO/1164393341/Machinelearn/data_test_final.mat')['data_test_final']\n",
    "\n",
    "#标准化数据\n",
    "data = preprocessing.StandardScaler().fit_transform(data)\n",
    "\n",
    "#预测\n",
    "test = rf.predict(data)\n",
    "dat = pd.DataFrame(test)\n",
    "\n",
    "#导出结果\n",
    "dat.to_csv('test-随机森林1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
